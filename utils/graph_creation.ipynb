{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad46d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122abf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_users.json\", \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(\"../data/all_problems.json\", \"r\") as f:\n",
    "    problems = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4b439",
   "metadata": {},
   "source": [
    "Clean the data\n",
    "- Remove any users without any solved problems\n",
    "- Remove any problems that have not been solved by any user\n",
    "- Save the cleaned data back to JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849c0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty users: 28\n",
      "Number of unsolved problems: 4\n"
     ]
    }
   ],
   "source": [
    "# TODO: Here we will also need to remove any problems \n",
    "# for which we couldn't get the hold information\n",
    "\n",
    "empty_users = []\n",
    "problems_solved = set()\n",
    "for key, user in users.items():\n",
    "    if not \"problems\" in user or len(user[\"problems\"]) == 0:\n",
    "        empty_users.append(key)\n",
    "    else:\n",
    "        for prob in user[\"problems\"].keys():\n",
    "            problems_solved.add(prob)\n",
    "print(f\"Number of empty users: {len(empty_users)}\")\n",
    "\n",
    "\n",
    "empty_problems = []\n",
    "for key in problems.keys():\n",
    "    if key not in problems_solved:\n",
    "        empty_problems.append(key)\n",
    "print(f\"Number of unsolved problems: {len(empty_problems)}\")\n",
    "\n",
    "for user_id in empty_users:\n",
    "    del users[user_id]\n",
    "for problem_id in empty_problems:\n",
    "    del problems[problem_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88057d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of user_ids: 25837\n",
      "Num of problems: 38659\n"
     ]
    }
   ],
   "source": [
    "user_ids = list(users.keys())\n",
    "problem_ids = list(problems.keys())\n",
    "\n",
    "# Integer ids are needed for PyG tensors\n",
    "user_id_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "problem_id_to_idx = {pid: i for i, pid in enumerate(problem_ids)}\n",
    "\n",
    "print(f\"Num of user_ids: {len(user_ids)}\\nNum of problems: {len(problem_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a33009",
   "metadata": {},
   "source": [
    "### Feature \"Engineering\" (Converting non-numeric to numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc4263",
   "metadata": {},
   "source": [
    "### Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e498b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade to index mapping: [('5+', 0), ('6A', 1), ('6A+', 2), ('6B', 3), ('6B+', 4)]...\n"
     ]
    }
   ],
   "source": [
    "# Collect all GRADES observed in users and problems\n",
    "grades = set()\n",
    "for u in users.values():\n",
    "    if u['highest_grade'] is not None:\n",
    "        grades.add(u['highest_grade'])\n",
    "    for pinfo in u['problems'].values():\n",
    "        if pinfo['grade'] is not None:\n",
    "            grades.add(pinfo['grade'])\n",
    "\n",
    "for p in problems.values():\n",
    "    if p['grade'] is not None:\n",
    "        grades.add(p['grade'])\n",
    "\n",
    "grades = sorted(grades)\n",
    "grade_to_idx = {g: i for i, g in enumerate(grades)}\n",
    "\n",
    "print(f\"Grade to index mapping: {list(grade_to_idx.items())[:5]}...\")\n",
    "\n",
    "def encode_grade(g):\n",
    "    # Encode grade g to its integer index, or -1 if g is None\n",
    "    if g is None:\n",
    "        return -1\n",
    "    return grade_to_idx[g]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6420904",
   "metadata": {},
   "source": [
    "TODO: User Bio\\\n",
    "I see two options here:\n",
    "- Use simple sentiment analysis to convert comments to numeric values between -1 and 1 (simple, low effort, low memory, low expressiveness)\n",
    "- Ignore comments for now (easy, but loses information)\n",
    "Computing embeddings would be too memory-intensive for possibly not much gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fc9ae",
   "metadata": {},
   "source": [
    "TODO: User problem comment\n",
    "- Same as for User Bio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134883aa",
   "metadata": {},
   "source": [
    "TODO: Problem Setter\n",
    "- Hashing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61783ac0",
   "metadata": {},
   "source": [
    "TODO: Problem holds (\"Any marked holds\" / \"Footless\" / \"Screw ons only\" / ...)\n",
    "- One-hot encoding or hashing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60a0f8",
   "metadata": {},
   "source": [
    "### Node feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab20b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature matrix shape: torch.Size([25837, 5])\n"
     ]
    }
   ],
   "source": [
    "user_features = []\n",
    "\n",
    "for uid in user_ids:\n",
    "    user = users[uid]\n",
    "\n",
    "    # All current numerical features\n",
    "    ranking = float(user['ranking']) if user['ranking'] is not None else 0.0\n",
    "    highest_grade_idx = float(encode_grade(user['highest_grade']))\n",
    "    height = float(user['height']) if user['height'] is not None else 0.0\n",
    "    weight = float(user['weight']) if user['weight'] is not None else 0.0\n",
    "    problems_sent = float(user['problems_sent']) if user['problems_sent'] is not None else 0.0\n",
    "    # bio = \n",
    "\n",
    "    user_features.append([ranking, highest_grade_idx, height, weight, problems_sent])\n",
    "\n",
    "user_x = torch.tensor(user_features, dtype=torch.float)\n",
    "print(f\"User feature matrix shape: {user_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1951084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem feature matrix shape: torch.Size([38659, 3])\n"
     ]
    }
   ],
   "source": [
    "problem_features = []\n",
    "\n",
    "for pid in problem_ids:\n",
    "    problem = problems[pid]\n",
    "\n",
    "    # All current numerical features\n",
    "    grade_idx = float(encode_grade(problem['grade']))\n",
    "    rating = float(problem['rating']) if problem['rating'] is not None else 0.0\n",
    "    num_sends = float(problem['num_sends']) if problem['num_sends'] is not None else 0.0\n",
    "    # setter =\n",
    "    # holds =\n",
    "\n",
    "    problem_features.append([grade_idx, rating, num_sends])\n",
    "\n",
    "problem_x = torch.tensor(problem_features, dtype=torch.float)\n",
    "print(f\"Problem feature matrix shape: {problem_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e6b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index shape: torch.Size([2, 1668865])\n",
      "Edge attribute shape: torch.Size([1668865, 3])\n",
      "Edge time shape: torch.Size([1668865])\n"
     ]
    }
   ],
   "source": [
    "user_indices = []\n",
    "problem_indices = []\n",
    "edge_grades = []\n",
    "edge_ratings = []\n",
    "edge_dates = []\n",
    "edge_attempts = []\n",
    "# edge_comments = []\n",
    "\n",
    "for uid, u in users.items():\n",
    "    u_idx = user_id_to_idx[uid]\n",
    "    for prob_name, interaction in u[\"problems\"].items():\n",
    "        if prob_name not in problem_id_to_idx:\n",
    "            # Just in case we missed removing some problems\n",
    "            continue\n",
    "\n",
    "        p_idx = problem_id_to_idx[prob_name]\n",
    "\n",
    "        user_indices.append(u_idx)\n",
    "        problem_indices.append(p_idx)\n",
    "\n",
    "        edge_grades.append(float(encode_grade(interaction[\"grade\"])))\n",
    "        edge_ratings.append(\n",
    "            float(interaction[\"rating\"]) if interaction[\"rating\"] is not None else 0.0\n",
    "        )\n",
    "        edge_attempts.append(\n",
    "            float(interaction[\"attempts\"])\n",
    "            if interaction[\"attempts\"] is not None\n",
    "            else 0.0\n",
    "        )\n",
    "        edge_dates.append(\n",
    "            time.mktime(datetime.datetime.strptime(interaction[\"date\"], \"%Y-%m-%d\").timetuple())\n",
    "        ) # Unix timestamp\n",
    "        # edge_comments.append(...)\n",
    "\n",
    "edge_index = torch.tensor([user_indices, problem_indices], dtype=torch.long)\n",
    "edge_attr = torch.tensor(\n",
    "    list(zip(edge_grades, edge_ratings, edge_attempts)),  # shape: [num_edges, 3]\n",
    "    dtype=torch.float,\n",
    ")\n",
    "edge_time = torch.tensor(edge_dates, dtype=torch.float)\n",
    "\n",
    "print(f\"Edge index shape: {edge_index.shape}\")\n",
    "print(f\"Edge attribute shape: {edge_attr.shape}\")\n",
    "print(f\"Edge time shape: {edge_time.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262c17b",
   "metadata": {},
   "source": [
    "### Assembling the HeteroData object (heterogeneous graph)\n",
    "\n",
    "- This graph is perfect for PinSAGE, which can prefers heterogeneous graphs with node and edge features.\n",
    "- For GFormer, we might need to make some adjustments.\n",
    "- For LightGCN, we need a homogeneous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_data = HeteroData()\n",
    "\n",
    "hetero_data['user'].x = user_x                 # [num_users, user_feat_dim]\n",
    "hetero_data['problem'].x = problem_x           # [num_problems, problem_feat_dim]\n",
    "\n",
    "hetero_data['user', 'rates', 'problem'].edge_index = edge_index      # [2, num_edges]\n",
    "hetero_data['user', 'rates', 'problem'].edge_attr = edge_attr        # [num_edges, edge_feat_dim]\n",
    "hetero_data['user', 'rates', 'problem'].edge_time = edge_time        # [num_edges,]\n",
    "\n",
    "# Add reverse edges (apparently good for GNN message passing):\n",
    "rev_edge_index = edge_index.flip(0)\n",
    "hetero_data['problem', 'rev_rates', 'user'].edge_index = rev_edge_index\n",
    "hetero_data['problem', 'rev_rates', 'user'].edge_attr = edge_attr  # usually same attrs\n",
    "hetero_data['problem', 'rev_rates', 'user'].edge_time = edge_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7004ea5",
   "metadata": {},
   "source": [
    "### Assembling the Data object (graph)\n",
    "- This is for LightGCN, which only supports homogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef853ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hetero_data.to_homogeneous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
