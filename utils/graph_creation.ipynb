{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1ad46d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "122abf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/all_users.json\", \"r\") as f:\n",
    "    users = json.load(f)\n",
    "\n",
    "with open(\"../data/all_problems.json\", \"r\") as f:\n",
    "    problems = json.load(f)\n",
    "\n",
    "with open(\"../data/all_holds.json\", \"r\") as f:\n",
    "    problem_holds = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4b439",
   "metadata": {},
   "source": [
    "Clean the data\n",
    "- Remove any users without any solved problems\n",
    "- Remove any problems that have not been solved by any user\n",
    "- Save the cleaned data back to JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ac4f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique holds: 198\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary where the unique holds are the keys and \n",
    "# the values are the problems associated with each hold\n",
    "holds = defaultdict(lambda: {\"start\":[], \"middle\": [], \"end\": []})\n",
    "\n",
    "for problem, pholds in problem_holds.items():\n",
    "    for section in (\"start\", \"middle\", \"end\"):\n",
    "        for hold in pholds[section]:\n",
    "            holds[hold][section].append(problem)\n",
    "\n",
    "holds = dict(holds)\n",
    "\n",
    "print(f\"Number of unique holds: {len(holds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33de2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the keys in problems to match those in holds\n",
    "problems = {key.replace(\" \", \"_\"): value for key, value in problems.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "849c0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problems with no holds: 4084\n",
      "Number of empty users: 39\n"
     ]
    }
   ],
   "source": [
    "# Remove problems that have no holds\n",
    "valid_problems = set(problem_holds.keys())\n",
    "problems_no_holds = []\n",
    "for key in problems.keys():\n",
    "    if key not in valid_problems:\n",
    "        problems_no_holds.append(key)\n",
    "\n",
    "print(f\"Number of problems with no holds: {len(problems_no_holds)}\")\n",
    "\n",
    "# Remove users that have no problems or no valid problems\n",
    "# and clean up their problems field accordingly\n",
    "empty_users = []\n",
    "for key, user in users.items():\n",
    "    if not \"problems\" in user:\n",
    "        # Remove the user if they have no problems field\n",
    "        empty_users.append(key)\n",
    "    else:\n",
    "        # Remove all the problems that are not in valid_problems\n",
    "        user_problems = user[\"problems\"]\n",
    "        filtered_problems = {\n",
    "            problem.replace(\" \", \"_\"): value\n",
    "            for problem, value in user_problems.items()\n",
    "            if problem.replace(\" \", \"_\") in valid_problems\n",
    "        }\n",
    "        # If the user has no problems left, mark them for removal\n",
    "        if len(filtered_problems) == 0:\n",
    "            empty_users.append(key)\n",
    "        else:\n",
    "            users[key][\"problems\"] = filtered_problems\n",
    "\n",
    "print(f\"Number of empty users: {len(empty_users)}\")\n",
    "\n",
    "for user_id in empty_users:\n",
    "    del users[user_id]\n",
    "for problem_id in problems_no_holds:\n",
    "    del problems[problem_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "88057d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of user_ids: 25826\n",
      "Num of problems: 34572\n",
      "Num of holds: 198\n"
     ]
    }
   ],
   "source": [
    "user_ids = list(users.keys())\n",
    "problem_ids = list(problems.keys())\n",
    "hold_ids = list(holds.keys())\n",
    "\n",
    "# Integer ids are needed for PyG tensors\n",
    "user_id_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "problem_id_to_idx = {pid: i for i, pid in enumerate(problem_ids)}\n",
    "hold_id_to_idx = {hid: i for i, hid in enumerate(hold_ids)}\n",
    "\n",
    "print(f\"Num of user_ids: {len(user_ids)}\\nNum of problems: {len(problem_ids)}\\nNum of holds: {len(hold_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a33009",
   "metadata": {},
   "source": [
    "### Feature \"Engineering\" (Converting non-numeric to numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc4263",
   "metadata": {},
   "source": [
    "### Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e498b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade to index mapping: [('5+', 0), ('6A', 1), ('6A+', 2), ('6B', 3), ('6B+', 4)]...\n"
     ]
    }
   ],
   "source": [
    "# Collect all GRADES observed in users and problems\n",
    "grades = set()\n",
    "for u in users.values():\n",
    "    if u['highest_grade'] is not None:\n",
    "        grades.add(u['highest_grade'])\n",
    "    for pinfo in u['problems'].values():\n",
    "        if pinfo['grade'] is not None:\n",
    "            grades.add(pinfo['grade'])\n",
    "\n",
    "for p in problems.values():\n",
    "    if p['grade'] is not None:\n",
    "        grades.add(p['grade'])\n",
    "\n",
    "grades = sorted(grades)\n",
    "grade_to_idx = {g: i for i, g in enumerate(grades)}\n",
    "\n",
    "print(f\"Grade to index mapping: {list(grade_to_idx.items())[:5]}...\")\n",
    "\n",
    "def encode_grade(g):\n",
    "    # Encode grade g to its integer index, or -1 if g is None\n",
    "    if g is None:\n",
    "        return -1\n",
    "    return grade_to_idx[g]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6420904",
   "metadata": {},
   "source": [
    "TODO: User Bio\\\n",
    "I see two options here:\n",
    "- Use simple sentiment analysis to convert comments to numeric values between -1 and 1 (simple, low effort, low memory, low expressiveness)\n",
    "- Ignore comments for now (easy, but loses information)\n",
    "Computing embeddings would be too memory-intensive for possibly not much gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fc9ae",
   "metadata": {},
   "source": [
    "TODO: User problem comment\n",
    "- Same as for User Bio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134883aa",
   "metadata": {},
   "source": [
    "TODO: Problem Setter\n",
    "- Hashing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61783ac0",
   "metadata": {},
   "source": [
    "TODO: Problem holds (\"Any marked holds\" / \"Footless\" / \"Screw ons only\" / ...)\n",
    "- One-hot encoding or hashing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60a0f8",
   "metadata": {},
   "source": [
    "### Node feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cab20b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature matrix shape: torch.Size([25826, 5])\n"
     ]
    }
   ],
   "source": [
    "user_features = []\n",
    "\n",
    "for uid in user_ids:\n",
    "    user = users[uid]\n",
    "\n",
    "    # All current numerical features\n",
    "    ranking = float(user['ranking']) if user['ranking'] is not None else 0.0\n",
    "    highest_grade_idx = float(encode_grade(user['highest_grade']))\n",
    "    height = float(user['height']) if user['height'] is not None else 0.0\n",
    "    weight = float(user['weight']) if user['weight'] is not None else 0.0\n",
    "    problems_sent = float(user['problems_sent']) if user['problems_sent'] is not None else 0.0\n",
    "    # bio = \n",
    "\n",
    "    user_features.append([ranking, highest_grade_idx, height, weight, problems_sent])\n",
    "\n",
    "user_x = torch.tensor(user_features, dtype=torch.float)\n",
    "print(f\"User feature matrix shape: {user_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f1951084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem feature matrix shape: torch.Size([34572, 3])\n"
     ]
    }
   ],
   "source": [
    "problem_features = []\n",
    "\n",
    "for pid in problem_ids:\n",
    "    problem = problems[pid]\n",
    "\n",
    "    # All current numerical features\n",
    "    grade_idx = float(encode_grade(problem['grade']))\n",
    "    rating = float(problem['rating']) if problem['rating'] is not None else 0.0\n",
    "    num_sends = float(problem['num_sends']) if problem['num_sends'] is not None else 0.0\n",
    "    # setter =\n",
    "    # holds =\n",
    "\n",
    "    problem_features.append([grade_idx, rating, num_sends])\n",
    "\n",
    "problem_x = torch.tensor(problem_features, dtype=torch.float)\n",
    "print(f\"Problem feature matrix shape: {problem_x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494d20f",
   "metadata": {},
   "source": [
    "### Graph edge index matrices with edge attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9286e",
   "metadata": {},
   "source": [
    "User-Problem edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c5e6b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index shape: torch.Size([2, 1627580])\n",
      "Edge attribute shape: torch.Size([1627580, 3])\n",
      "Edge time shape: torch.Size([1627580])\n"
     ]
    }
   ],
   "source": [
    "up_user_indices = []\n",
    "up_problem_indices = []\n",
    "up_edge_grades = []\n",
    "up_edge_ratings = []\n",
    "up_edge_dates = []\n",
    "up_edge_attempts = []\n",
    "# edge_comments = []\n",
    "\n",
    "for uid, u in users.items():\n",
    "    u_idx = user_id_to_idx[uid]\n",
    "    for prob_name, interaction in u[\"problems\"].items():\n",
    "        if prob_name not in problem_id_to_idx:\n",
    "            # Just in case we missed removing some problems\n",
    "            continue\n",
    "\n",
    "        p_idx = problem_id_to_idx[prob_name]\n",
    "\n",
    "        up_user_indices.append(u_idx)\n",
    "        up_problem_indices.append(p_idx)\n",
    "\n",
    "        up_edge_grades.append(float(encode_grade(interaction[\"grade\"])))\n",
    "        up_edge_ratings.append(\n",
    "            float(interaction[\"rating\"]) if interaction[\"rating\"] is not None else 0.0\n",
    "        )\n",
    "        up_edge_attempts.append(\n",
    "            float(interaction[\"attempts\"])\n",
    "            if interaction[\"attempts\"] is not None\n",
    "            else 0.0\n",
    "        )\n",
    "        up_edge_dates.append(\n",
    "            time.mktime(datetime.datetime.strptime(interaction[\"date\"], \"%Y-%m-%d\").timetuple())\n",
    "        ) # Unix timestamp\n",
    "        # edge_comments.append(...)\n",
    "\n",
    "up_edge_index = torch.tensor([up_user_indices, up_problem_indices], dtype=torch.long)\n",
    "up_edge_attr = torch.tensor(\n",
    "    list(zip(up_edge_grades, up_edge_ratings, up_edge_attempts)),  # shape: [num_edges, 3]\n",
    "    dtype=torch.float,\n",
    ")\n",
    "up_edge_time = torch.tensor(up_edge_dates, dtype=torch.float)\n",
    "\n",
    "print(f\"Edge index shape: {up_edge_index.shape}\")\n",
    "print(f\"Edge attribute shape: {up_edge_attr.shape}\")\n",
    "print(f\"Edge time shape: {up_edge_time.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0628a81",
   "metadata": {},
   "source": [
    "Problem-Hold edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b63259a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index shape: torch.Size([2, 304852])\n",
      "Edge attribute shape: torch.Size([304852, 3])\n"
     ]
    }
   ],
   "source": [
    "hp_hold_indices = []\n",
    "hp_problem_indices = []\n",
    "hp_is_start = []\n",
    "hp_is_middle = []\n",
    "hp_is_end = []\n",
    "\n",
    "for hold, problems in holds.items():\n",
    "    h_idx = hold_id_to_idx[hold]\n",
    "    for type in (\"start\", \"middle\", \"end\"):\n",
    "        for problem in problems[type]:\n",
    "            p_idx = problem_id_to_idx[problem]\n",
    "\n",
    "            hp_hold_indices.append(h_idx)\n",
    "            hp_problem_indices.append(p_idx)\n",
    "\n",
    "            hp_is_start.append(int(type == \"start\"))\n",
    "            hp_is_middle.append(int(type == \"middle\"))\n",
    "            hp_is_end.append(int(type == \"end\"))\n",
    "\n",
    "hp_edge_index = torch.tensor([hp_hold_indices, hp_problem_indices], dtype=torch.long)\n",
    "hp_edge_attr = torch.tensor(list(zip(hp_is_start, hp_is_middle, hp_is_end)), dtype=torch.float)\n",
    "\n",
    "print(f\"Edge index shape: {hp_edge_index.shape}\")\n",
    "print(f\"Edge attribute shape: {hp_edge_attr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262c17b",
   "metadata": {},
   "source": [
    "### Assembling the HeteroData object (heterogeneous graph)\n",
    "\n",
    "- This graph is perfect for PinSAGE, which can prefers heterogeneous graphs with node and edge features.\n",
    "- For GFormer, we might need to make some adjustments.\n",
    "- For LightGCN, we need a homogeneous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "306863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_data = HeteroData()\n",
    "\n",
    "# Add the nodes and their features\n",
    "hetero_data['user'].x = user_x                    # [num_users, user_feat_dim]\n",
    "hetero_data['problem'].x = problem_x              # [num_problems, problem_feat_dim]\n",
    "hetero_data['hold'].x = torch.eye(len(hold_ids))  # One-hot encoding for holds\n",
    "\n",
    "# Add edges between users and problems\n",
    "hetero_data['user', 'rates', 'problem'].edge_index = up_edge_index      # [2, num_edges]\n",
    "hetero_data['user', 'rates', 'problem'].edge_attr = up_edge_attr        # [num_edges, edge_feat_dim]\n",
    "hetero_data['user', 'rates', 'problem'].edge_time = up_edge_time        # [num_edges,]\n",
    "\n",
    "# Add reverse edges (apparently good for GNN message passing):\n",
    "hetero_data['problem', 'rated_by', 'user'].edge_index = up_edge_index.flip(0)\n",
    "hetero_data['problem', 'rated_by', 'user'].edge_attr = up_edge_attr  # usually same attrs\n",
    "hetero_data['problem', 'rated_by', 'user'].edge_time = up_edge_time\n",
    "\n",
    "# Add edges between problems and holds\n",
    "hetero_data['problem', 'contains', 'hold'].edge_index = hp_edge_index\n",
    "hetero_data['problem', 'contains', 'hold'].edge_attr = hp_edge_attr\n",
    "\n",
    "# Add reverse edges\n",
    "hetero_data['hold', 'contained_in', 'problem'].edge_index = hp_edge_index.flip(0)\n",
    "hetero_data['hold', 'contained_in', 'problem'].edge_attr = hp_edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7004ea5",
   "metadata": {},
   "source": [
    "### Assembling the Data object (graph)\n",
    "- This is for LightGCN, which only supports homogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ef853ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hetero_data.to_homogeneous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
