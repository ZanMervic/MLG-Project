{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e06fed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.graph_creation import create_hetero_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beecc99",
   "metadata": {},
   "source": [
    "# Dataset Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d2d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 25865\n",
      "Total ascends: 1668865\n",
      "Total ascends: 1807394\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/all_users.json\", \"r\") as f:\n",
    "    all_users = json.load(f)\n",
    "\n",
    "print(f\"Total users: {len(all_users)}\")\n",
    "\n",
    "num_ascends = 0\n",
    "for user in all_users.values():\n",
    "    num_ascends += len(user.get(\"problems\", []))\n",
    "print(f\"Total ascends: {num_ascends}\")\n",
    "\n",
    "num_ascends = 0\n",
    "for user in all_users.values():\n",
    "    num_ascends += user.get(\"problems_sent\", 0)\n",
    "print(f\"Total ascends: {num_ascends}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2faf2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total problems: 38663\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/all_problems.json\", \"r\") as f:\n",
    "    all_problems = json.load(f)\n",
    "\n",
    "print(f\"Total problems: {len(all_problems)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee7230",
   "metadata": {},
   "source": [
    "# Graph Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b18ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_graph = create_hetero_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14cf8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_hetero_graph(holds_as_nodes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46022f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def analyze_hetero_graph(data, name=\"Graph\"):\n",
    "    \"\"\"\n",
    "    Analyze a HeteroData graph and compute various statistics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analysis for: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. Number of nodes of each type\n",
    "    print(\"\\n--- Number of Nodes per Type ---\")\n",
    "    total_nodes = 0\n",
    "    node_types = data.node_types\n",
    "    for node_type in node_types:\n",
    "        num_nodes = data[node_type].x.shape[0]\n",
    "        print(f\"  {node_type}: {num_nodes:,}\")\n",
    "        total_nodes += num_nodes\n",
    "    print(f\"  Total: {total_nodes:,}\")\n",
    "    \n",
    "    # 2. Number of edges of each type\n",
    "    print(\"\\n--- Number of Edges per Type ---\")\n",
    "    total_edges = 0\n",
    "    edge_types = data.edge_types\n",
    "    for edge_type in edge_types:\n",
    "        num_edges = data[edge_type].edge_index.shape[1]\n",
    "        print(f\"  {edge_type}: {num_edges:,}\")\n",
    "        total_edges += num_edges\n",
    "    # Divide by 2 since we have reverse edges\n",
    "    print(f\"  Total (including reverse): {total_edges:,}\")\n",
    "    print(f\"  Total (unique): {total_edges // 2:,}\")\n",
    "    \n",
    "    # Convert to homogeneous NetworkX graph for global metrics\n",
    "    print(\"\\n--- Converting to NetworkX (this may take a moment) ---\")\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Create node mappings to global indices\n",
    "    node_offset = {}\n",
    "    current_offset = 0\n",
    "    for node_type in node_types:\n",
    "        node_offset[node_type] = current_offset\n",
    "        num_nodes = data[node_type].x.shape[0]\n",
    "        # Add nodes with type attribute\n",
    "        G.add_nodes_from(\n",
    "            [(current_offset + i, {'type': node_type}) for i in range(num_nodes)]\n",
    "        )\n",
    "        current_offset += num_nodes\n",
    "    \n",
    "    # Add edges (only non-reverse to avoid duplicates)\n",
    "    for edge_type in edge_types:\n",
    "        src_type, rel, dst_type = edge_type\n",
    "        if rel.startswith('rev_'):\n",
    "            continue  # Skip reverse edges\n",
    "        \n",
    "        edge_index = data[edge_type].edge_index.numpy()\n",
    "        src_offset = node_offset[src_type]\n",
    "        dst_offset = node_offset[dst_type]\n",
    "        \n",
    "        edges = [\n",
    "            (src_offset + edge_index[0, i], dst_offset + edge_index[1, i])\n",
    "            for i in range(edge_index.shape[1])\n",
    "        ]\n",
    "        G.add_edges_from(edges)\n",
    "    \n",
    "    print(f\"  NetworkX graph: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges\")\n",
    "    \n",
    "    # 3. Number of connected components\n",
    "    print(\"\\n--- Connected Components ---\")\n",
    "    num_components = nx.number_connected_components(G)\n",
    "    print(f\"  Number of connected components: {num_components:,}\")\n",
    "    \n",
    "    # Get largest component for diameter calculation\n",
    "    if num_components > 1:\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G_largest = G.subgraph(largest_cc).copy()\n",
    "        print(f\"  Largest component size: {G_largest.number_of_nodes():,} nodes\")\n",
    "    else:\n",
    "        G_largest = G\n",
    "    \n",
    "    # 4. Graph Diameter (on largest connected component)\n",
    "    # For large graphs, exact diameter is expensive - use approximation\n",
    "    print(\"\\n--- Graph Diameter (largest component) ---\")\n",
    "    if G_largest.number_of_nodes() > 10000:\n",
    "        # Use approximation for large graphs\n",
    "        try:\n",
    "            diameter_approx = nx.approximation.diameter(G_largest)\n",
    "            print(f\"  Approximate diameter: {diameter_approx}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Diameter computation failed: {e}\")\n",
    "    else:\n",
    "        diameter = nx.diameter(G_largest)\n",
    "        print(f\"  Exact diameter: {diameter}\")\n",
    "    \n",
    "    # 5. Graph Density\n",
    "    print(\"\\n--- Graph Density ---\")\n",
    "    density = nx.density(G)\n",
    "    print(f\"  Density: {density:.6e}\")\n",
    "    \n",
    "    # 6. Average Clustering Coefficient\n",
    "    # For large graphs, sample nodes to compute approximate clustering\n",
    "    print(\"\\n--- Average Clustering Coefficient ---\")\n",
    "    if G.number_of_nodes() > 50000:\n",
    "        # Sample nodes for approximation\n",
    "        sample_size = min(10000, G.number_of_nodes())\n",
    "        sampled_nodes = random.sample(list(G.nodes()), sample_size)\n",
    "        avg_clustering = nx.average_clustering(G, nodes=sampled_nodes)\n",
    "        print(f\"  Approximate average clustering (sample of {sample_size:,}): {avg_clustering:.6f}\")\n",
    "    else:\n",
    "        avg_clustering = nx.average_clustering(G)\n",
    "        print(f\"  Average clustering coefficient: {avg_clustering:.6f}\")\n",
    "    \n",
    "    # 7. Node Degree Distribution for each node type\n",
    "    print(\"\\n--- Node Degree Distribution per Type ---\")\n",
    "    for node_type in node_types:\n",
    "        offset = node_offset[node_type]\n",
    "        num_nodes = data[node_type].x.shape[0]\n",
    "        node_ids = range(offset, offset + num_nodes)\n",
    "        \n",
    "        degrees = [G.degree(n) for n in node_ids]\n",
    "        degrees = np.array(degrees)\n",
    "        \n",
    "        print(f\"\\n  {node_type}:\")\n",
    "        print(f\"    Min degree: {degrees.min()}\")\n",
    "        print(f\"    Max degree: {degrees.max()}\")\n",
    "        print(f\"    Mean degree: {degrees.mean():.2f}\")\n",
    "        print(f\"    Median degree: {np.median(degrees):.2f}\")\n",
    "        print(f\"    Std degree: {degrees.std():.2f}\")\n",
    "        \n",
    "        # Show degree distribution (top 5 most common)\n",
    "        degree_counts = Counter(degrees)\n",
    "        most_common = degree_counts.most_common(5)\n",
    "        print(f\"    Top 5 most common degrees: {most_common}\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4abe59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Analysis for: HeteroGraph WITH hold nodes\n",
      "============================================================\n",
      "\n",
      "--- Number of Nodes per Type ---\n",
      "  user: 25,826\n",
      "  problem: 34,572\n",
      "  hold: 198\n",
      "  Total: 60,596\n",
      "\n",
      "--- Number of Edges per Type ---\n",
      "  ('user', 'rates', 'problem'): 1,627,580\n",
      "  ('problem', 'rev_rates', 'user'): 1,627,580\n",
      "  ('problem', 'contains', 'hold'): 304,852\n",
      "  ('hold', 'rev_contains', 'problem'): 304,852\n",
      "  Total (including reverse): 3,864,864\n",
      "  Total (unique): 1,932,432\n",
      "\n",
      "--- Converting to NetworkX (this may take a moment) ---\n",
      "  NetworkX graph: 60,596 nodes, 1,932,432 edges\n",
      "\n",
      "--- Connected Components ---\n",
      "  Number of connected components: 1\n",
      "\n",
      "--- Graph Diameter (largest component) ---\n",
      "  Approximate diameter: 6\n",
      "\n",
      "--- Graph Density ---\n",
      "  Density: 1.052576e-03\n",
      "\n",
      "--- Average Clustering Coefficient ---\n",
      "  Approximate average clustering (sample of 10,000): 0.000000\n",
      "\n",
      "--- Node Degree Distribution per Type ---\n",
      "\n",
      "  user:\n",
      "    Min degree: 1\n",
      "    Max degree: 3676\n",
      "    Mean degree: 63.02\n",
      "    Median degree: 20.00\n",
      "    Std degree: 118.73\n",
      "    Top 5 most common degrees: [(1, 1893), (2, 1529), (3, 1290), (4, 1011), (5, 868)]\n",
      "\n",
      "  problem:\n",
      "    Min degree: 3\n",
      "    Max degree: 14861\n",
      "    Mean degree: 55.90\n",
      "    Median degree: 12.00\n",
      "    Std degree: 459.03\n",
      "    Top 5 most common degrees: [(10, 3779), (9, 3641), (11, 3448), (12, 3050), (8, 2698)]\n",
      "\n",
      "  hold:\n",
      "    Min degree: 42\n",
      "    Max degree: 8663\n",
      "    Mean degree: 1539.66\n",
      "    Median degree: 1017.50\n",
      "    Std degree: 1470.20\n",
      "    Top 5 most common degrees: [(510, 2), (3193, 2), (880, 2), (189, 2), (644, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Analyze the graph WITH hold nodes\n",
    "G_with_holds = analyze_hetero_graph(hetero_graph, \"HeteroGraph WITH hold nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d49feee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Analysis for: HeteroGraph WITHOUT hold nodes\n",
      "============================================================\n",
      "\n",
      "--- Number of Nodes per Type ---\n",
      "  user: 25,826\n",
      "  problem: 34,572\n",
      "  Total: 60,398\n",
      "\n",
      "--- Number of Edges per Type ---\n",
      "  ('user', 'rates', 'problem'): 1,627,580\n",
      "  ('problem', 'rev_rates', 'user'): 1,627,580\n",
      "  Total (including reverse): 3,255,160\n",
      "  Total (unique): 1,627,580\n",
      "\n",
      "--- Converting to NetworkX (this may take a moment) ---\n",
      "  NetworkX graph: 60,398 nodes, 1,627,580 edges\n",
      "\n",
      "--- Connected Components ---\n",
      "  Number of connected components: 6\n",
      "  Largest component size: 60,390 nodes\n",
      "\n",
      "--- Graph Diameter (largest component) ---\n",
      "  Approximate diameter: 7\n",
      "\n",
      "--- Graph Density ---\n",
      "  Density: 8.923483e-04\n",
      "\n",
      "--- Average Clustering Coefficient ---\n",
      "  Approximate average clustering (sample of 10,000): 0.000000\n",
      "\n",
      "--- Node Degree Distribution per Type ---\n",
      "\n",
      "  user:\n",
      "    Min degree: 1\n",
      "    Max degree: 3676\n",
      "    Mean degree: 63.02\n",
      "    Median degree: 20.00\n",
      "    Std degree: 118.73\n",
      "    Top 5 most common degrees: [(1, 1893), (2, 1529), (3, 1290), (4, 1011), (5, 868)]\n",
      "\n",
      "  problem:\n",
      "    Min degree: 0\n",
      "    Max degree: 14850\n",
      "    Mean degree: 47.08\n",
      "    Median degree: 3.00\n",
      "    Std degree: 459.08\n",
      "    Top 5 most common degrees: [(1, 9689), (2, 6205), (3, 4083), (4, 2779), (5, 1904)]\n"
     ]
    }
   ],
   "source": [
    "# Analyze the graph WITHOUT hold nodes\n",
    "G_without_holds = analyze_hetero_graph(graph, \"HeteroGraph WITHOUT hold nodes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlg-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
